{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Name = 'Ati tesakulsiri'\n",
    "ID = 'st123009'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 0 Project path for code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python Project Path `/root/keep_lab/RTML_Labsession/04_y_olo3/to_submit`\n",
    "- From puffer `/home/corse/st123009/lab01/root/keep_lab/RTML_Labsession/04_y_olo3/to_submit`\n",
    "``` bash\n",
    ".\n",
    "├── __pycache__\n",
    "│   ├── darknet.cpython-38.pyc\n",
    "│   ├── mish_.cpython-38.pyc\n",
    "│   └── util.cpython-38.pyc\n",
    "├── cfg\n",
    "│   └── yolov3.cfg\n",
    "├── cocoimages\n",
    "│   └── dog-cycle-car.png\n",
    "├── darknet.py\n",
    "├── data\n",
    "│   └── coco.names\n",
    "├── des\n",
    "│   └── det_dog-cycle-car.png\n",
    "├── det\n",
    "│   └── det_dog-cycle-car.png\n",
    "├── detect.py\n",
    "├── mish_.py\n",
    "├── util.py\n",
    "└── yolov3.weights\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part 1 Introduction\n",
    "\n",
    "- #### Object detection\n",
    "The concept of object detection in computer vision includes identifying different things in digital photos or movies. Among the things found are people, vehicles, chairs, stones, structures, and animals.\n",
    "\n",
    "- #### YOLO\n",
    "YOLO is a method that provides real-time object detection using neural networks. The popularity of this algorithm is due to its accuracy and quickness. It has been applied in a variety of ways to identify animals, humans, parking meters, and traffic lights.\n",
    "\n",
    "The YOLO method for object detection is described in this article along with its workings. It also highlights a few of its practical uses.\n",
    "\n",
    "- #### Yolov4\n",
    "- YOLO v4 was developed based on YOLO v3 by a new group of authors, Alexey Bochkovskiy and colleagues, who took\n",
    "over the development of Darknet and YOLO after [Joseph Redmon quit computer vision research](https://twitter.com/pjreddie/status/1230524770350817280?lang=en).\n",
    "- Take a look at the [YOLO v4 paper](https://arxiv.org/abs/2004.10934). The authors make many small and some large\n",
    "improvements to YOLOv3 to achieve a higher frame rate and higher accuracy. Source code is available at the\n",
    "[Darknet GitHub repository](https://github.com/AlexeyAB/darknet).\n",
    "    - Bag of spacial \n",
    "\n",
    "        - Mish activation Function\n",
    "\n",
    "\n",
    "            - Next, let's take a look at the newish activation function used in YOLOv4: Mish.\n",
    "        Mish is a SoftPlus activation function that is non-monotonic and designed for\n",
    "        neural networks that regularize themselves. It was inspired by the *swish* activation function.\n",
    "        It has a range from -0.31 to $\\infty$, due to the SoftPlus function:\n",
    "\n",
    "$$\\mathrm{SoftPlus}(x)=\\ln(1+e^x) \\\\\n",
    "f(x)=x \\tanh(\\mathrm{SoftPlus}(x))=x \\tanh(\\ln(1+e^x)) $$.\n",
    "\n",
    "<img src = '/root/keep_lab/RTML_Labsession/04_y_olo3/to_submit/mish_activation_function_graph.png' title=\"weight\" style=\"width: 480px;\" />\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 Method\n",
    "   1. Implementation of the mish activation function\n",
    "   2. Option for the maxpool layer in the `create_modules` function and in your model's `forward()` method.\n",
    "   3. Enabling a `[route]` module to concatenate more than two previous layers\n",
    "   4. Loading the pre-trained weights [provided by the authors](https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.weights)\n",
    "   4. Scale inputs to 608,608 and make sure you're passing input channels in RGB order, not OpenCV's BGR order."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 result\n",
    "- ## 1. Mish\n",
    "    - In mish_.py we have\n",
    "\n",
    "    ``` python\n",
    "    import torch.nn as nn\n",
    "    import torch\n",
    "    import torch.nn.functional as F \n",
    "\n",
    "    class Mish(nn.Module):\n",
    "     def __init__(self):\n",
    "         super().__init__()\n",
    "\n",
    "     def forward(self, x):\n",
    "         return x * torch.tanh(F.softplus(x))\n",
    "\n",
    "    class LinearActivation(nn.Module):\n",
    "     def __init__(self):\n",
    "         super().__init__()\n",
    "\n",
    "     def forward(self, x):\n",
    "         return x\n",
    "\n",
    "    ```\n",
    "\n",
    "With in `X['type'] = 'convolutional`, we have\n",
    "```python\n",
    "            elif activation == \"mish\":\n",
    "                activn = Mish()\n",
    "                module.add_module(\"mish_{0}\".format(index), activn)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## 2. Resulution\n",
    "    - I have chage the input and scailing as following\n",
    "\n",
    "model input \n",
    "\n",
    "```python\n",
    "model.net_info[\"height\"] = 608\n",
    "inp_dim = int(model.net_info[\"height\"])\n",
    "```\n",
    " Scailing\n",
    "``` python\n",
    "scaling_factor = torch.min(608/im_dim_list,1)[0].view(-1,1)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  MORE route\n",
    "- This part I am not sure, thus I ask tonson and he told this\n",
    "\n",
    "\n",
    "In\n",
    "``` python\n",
    "\n",
    "elif (x[\"type\"] == \"route\"):\n",
    "```\n",
    "we add\n",
    "``` python\n",
    "    if end < 0:\n",
    "        filters = output_filters[index + start] + output_filters[index + end]\n",
    "    else:\n",
    "        filters= output_filters[index + start]\n",
    "    if(len(x[\"layers\"]) == 4):\n",
    "        filters = 2048`\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. load yolov4\n",
    "- we download from link in `lab direction` \n",
    "```bash \n",
    "root@10c86d735246:~/keep_lab/RTML_Labsession/04_y_olo3/to_submit# wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.weights\n",
    "--2023-02-09 03:25:31--  https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.weights\n",
    "Connecting to 192.41.170.23:3128... connected.\n",
    "Proxy request sent, awaiting response... 302 Found\n",
    "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/75388965/ba4b6380-889c-11ea-9751-f994f5961796?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230209%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230209T032531Z&X-Amz-Expires=300&X-Amz-Signature=637d7a22752cdb4577188e0192a0c3841a92f83ce1bbc79458435fdf6927acc2&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=75388965&response-content-disposition=attachment%3B%20filename%3Dyolov4.weights&response-content-type=application%2Foctet-stream [following]\n",
    "--2023-02-09 03:25:32--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/75388965/ba4b6380-889c-11ea-9751-f994f5961796?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230209%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230209T032531Z&X-Amz-Expires=300&X-Amz-Signature=637d7a22752cdb4577188e0192a0c3841a92f83ce1bbc79458435fdf6927acc2&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=75388965&response-content-disposition=attachment%3B%20filename%3Dyolov4.weights&response-content-type=application%2Foctet-stream\n",
    "Connecting to 192.41.170.23:3128... connected.\n",
    "Proxy request sent, awaiting response... 200 OK\n",
    "Length: 257717640 (246M) [application/octet-stream]\n",
    "Saving to: ‘yolov4.weights’\n",
    "\n",
    "yolov4.weights                                                      100%[===================================================================================================================================================================>] 245.78M  3.32MB/s    in 2m 14s  \n",
    "\n",
    "2023-02-09 03:27:47 (1.84 MB/s) - ‘yolov4.weights’ saved [257717640/257717640]\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "- ## After download we have\n",
    "\n",
    "```python \n",
    "model.load_weights(\"yolov3.weights\")\n",
    "model = Darknet(\"cfg/yolov4.cfg\") # This one I copied from github in lab direction provioded\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Max pool in forward\n",
    "- we add in forward\n",
    "```python\n",
    "if module_type in [\"convolutional\", \"upsample\", \"maxpool\"]:\n",
    "    x = self.modul_list[i](x)\n",
    "```\n",
    "- In module\n",
    "```python\n",
    "elif x[\"type\"] == \"maxpool\":\n",
    "    stride = int(x[\"stride\"])\n",
    "    size = int(x[\"size\"])\n",
    "    max_pool = nn.MaxPool2d(size, stride, padding=size//2)\n",
    "    module.add_module(\"maxpool_{}\".format(index), max_pool)\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "- After I done seem like there are some bug in the code\n",
    "as following result\n",
    "\n",
    "\n",
    "<img src ='des/det_dog-cycle-car.png'>\n",
    "\n",
    "In summnary\n",
    "``` bash\n",
    "----------------------------------------------------------\n",
    "SUMMARY\n",
    "----------------------------------------------------------\n",
    "Task                     : Time Taken (in seconds)\n",
    "\n",
    "Reading addresses        : 0.001\n",
    "Loading batch            : 0.026\n",
    "Detection (1 images)     : 20.155\n",
    "Output Processing        : 0.000\n",
    "Drawing Boxes            : 4.412\n",
    "Average time_per_img     : 24.593\n",
    "----------------------------------------------------------\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10 (default, Nov 26 2021, 20:14:08) \n[GCC 9.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
